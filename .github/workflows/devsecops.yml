name: Vuln Bank DevSecOps Pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

  # Konfigurasi Pemicu Manual
  workflow_dispatch:
    inputs:
      run_full_deploy:
        description: 'Konfirmasi: Jalankan Build, Push & Deploy ke Ansible?'
        required: true
        default: 'false'
        type: choice
        options: ['true', 'false']

permissions:
  contents: read
  security-events: write
  issues: write
  id-token: write

concurrency:
  group: vuln-bank-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  APP_NAME: vuln-bank
  APP_URL: http://192.168.107.135:5000

  REPORT_DIR: security-reports

  DOCKERHUB_REPO: ${{ secrets.DOCKERHUB_REPO }}
  IMAGE_TAG: ${{ github.sha }}
  DOCKERFILE_PATH: containers/app/Dockerfile
  REQUIREMENTS_PATH: containers/app/requirements.txt

  DEFECTDOJO_URL: ${{ secrets.DEFECTDOJO_URL }}
  DEFECTDOJO_API_KEY: ${{ secrets.DEFECTDOJO_API_KEY }}
  DEFECTDOJO_PRODUCT_ID: ${{ secrets.DEFECTDOJO_PRODUCT_ID }}
  DEFECTDOJO_ENGAGEMENT_NAME: "Build-${{ github.run_number }}"

  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # 2025 â€” LLM SAST Multistrategy
  LLM_SCAN_PATH: "."
  LLM_REPORT: "security-reports/llm-multi-agent.json"
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  AI_API_ENDPOINT: ${{ secrets.AI_API_ENDPOINT }}
  AI_API_KEY: ${{ secrets.AI_API_KEY }}

  FAIL_ON_SEVERITIES: "CRITICAL,HIGH"

  EPSS_MODE: "C"           # A=Strict, B=Weighted, C=Hybrid
  EPSS_THRESHOLD: "0.5"
  EPSS_FINDINGS: "security-reports/epss-findings.json"

# =====================================================================
# 1. SETUP
# =====================================================================
jobs:
  setup:
    name: Setup Runner Environment
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - name: Prepare workspace
        run: |
          set -euo pipefail
          mkdir -p "${REPORT_DIR}"
          python3 -m pip install --upgrade pip
          sudo dnf install -y jq pipx || true

      - name: Install Core Tools
        run: |
          set -euo pipefail
          if [ -f "${REQUIREMENTS_PATH}" ]; then
            pip install -r "${REQUIREMENTS_PATH}"
          fi

          export PATH="$HOME/.local/bin:$PATH"
          pipx install --force semgrep || true
          pipx install --force checkov || true

# =====================================================================
# 2. TRADITIONAL SECURITY SCANS
# =====================================================================
  security_scans:
    name: Traditional Security Scans
    needs: setup
    runs-on: self-hosted

    strategy:
      fail-fast: false
      matrix:
        scan_type: [trufflehog, semgrep, trivy, snyk, checkov, sonarqube]

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Init report dir
        run: mkdir -p "${REPORT_DIR}"

      # ------------- TruffleHog
      - name: TruffleHog
        if: matrix.scan_type == 'trufflehog'
        run: |
          set -euo pipefail
          trufflehog git file://$(pwd) \
            --json --only-verified --no-update \
            > "${REPORT_DIR}/trufflehog.json" || true

      # ------------- Semgrep
      - name: Semgrep Scan
        if: matrix.scan_type == 'semgrep'
        run: |
          set -euo pipefail
          semgrep scan \
            --config auto \
            --config p/security-audit \
            --config p/secrets \
            --config p/owasp-top-ten \
            --json > "${REPORT_DIR}/semgrep.json" || true

      # ------------- Checkov
      - name: Checkov Scan
        if: matrix.scan_type == 'checkov'
        run: |
          set -euo pipefail
          export PATH="$HOME/.local/bin:$PATH"
          checkov -d ansible --output json \
            > "${REPORT_DIR}/checkov_ansible.json" || true
          checkov -f "${DOCKERFILE_PATH}" --output json \
            > "${REPORT_DIR}/checkov_docker.json" || true

      # ------------- Trivy
      - name: Trivy Config
        if: matrix.scan_type == 'trivy'
        run: |
          set -euo pipefail
          trivy config . \
            --severity "${FAIL_ON_SEVERITIES}" \
            --format json \
            --output "${REPORT_DIR}/trivy.json" || true

      # ------------- Snyk
      - name: Snyk Scan
        if: matrix.scan_type == 'snyk'
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          set -euo pipefail
          snyk code test --json > "${REPORT_DIR}/snyk-code.json" || true
          snyk test --json > "${REPORT_DIR}/snyk-sca.json" || true

      # ------------- SonarQube
      - name: Python Coverage
        if: matrix.scan_type == 'sonarqube'
        run: |
          set -euo pipefail
          pip install pytest pytest-cov coverage
          mkdir -p security-reports
          pytest \
            --disable-warnings \
            --cov=. \
            --cov-report=xml:security-reports/coverage.xml \
            --cov-report=term || true

      - name: SonarQube
        if: matrix.scan_type == 'sonarqube'
        env:
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          set -euo pipefail
          sonar-scanner \
            -Dsonar.projectKey=vuln-bank \
            -Dsonar.sources=. \
            -Dsonar.exclusions="static/**,templates/**,*.md,LICENSE,*.txt" \
            -Dsonar.python.coverage.reportPaths=$(pwd)/security-reports/coverage.xml \
            -Dsonar.host.url="${SONAR_HOST_URL}" \
            -Dsonar.login="${SONAR_TOKEN}"

      # ------------- Upload artifacts
      - name: Upload artifacts
        if: matrix.scan_type != 'sonarqube'
        uses: actions/upload-artifact@v4
        with:
          name: reports-${{ matrix.scan_type }}
          path: ${{ env.REPORT_DIR }}/*.json
          if-no-files-found: warn
          retention-days: 14

# =====================================================================
# 3. LLM SAST MULTI-AGENT
# =====================================================================
  llm_sast:
    name: LLM SAST Multi-Agent
    needs: setup
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - name: Add repo to PYTHONPATH
        run: |
          echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Install LLM deps
        run: |
          set -euo pipefail
          pip install -r llm/requirements.txt

      - name: Run LLM scanner
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AI_API_ENDPOINT: ${{ secrets.AI_API_ENDPOINT }}
          AI_API_KEY: ${{ secrets.AI_API_KEY }}
          LLM_REPORT: ${{ env.LLM_REPORT }}
        run: |
          set -euo pipefail
          python -m llm.pipeline \
            --scan-path "${LLM_SCAN_PATH}" \
            --output "${LLM_REPORT}"

      - name: Upload LLM findings
        uses: actions/upload-artifact@v4
        with:
          name: llm-findings
          path: ${{ env.LLM_REPORT }}
          retention-days: 14

# =====================================================================
# 4. EPSS/KEV GATE + SUMMARY
# =====================================================================
  gate_and_summary:
    name: Security Gate + EPSS + Slack
    needs: [security_scans, llm_sast]
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          path: all-reports

      - name: Run EPSS Gate (Hybrid)
        env:
          EPSS_MODE: ${{ env.EPSS_MODE }}
          EPSS_THRESHOLD: ${{ env.EPSS_THRESHOLD }}
          EPSS_FINDINGS: ${{ env.EPSS_FINDINGS }}
        run: |
          set -euo pipefail
          mkdir -p "$(dirname "${EPSS_FINDINGS}")"

          TRIVY_INPUT="all-reports/reports-trivy/trivy.json"
          SNYK_SCA_INPUT="all-reports/reports-snyk/snyk-sca.json"

          inputs=()
          [ -f "${TRIVY_INPUT}" ] && inputs+=("--input" "${TRIVY_INPUT}")
          [ -f "${SNYK_SCA_INPUT}" ] && inputs+=("--input" "${SNYK_SCA_INPUT}")

          if [ "${#inputs[@]}" -eq 0 ]; then
            echo "[INFO] No Trivy/Snyk SCA reports found; skipping EPSS gate."
            echo '{"high_risk":[],"threshold":'"${EPSS_THRESHOLD}"'}' > "${EPSS_FINDINGS}"
          else
            python3 scripts/epss_gate.py \
              --mode "${EPSS_MODE}" \
              --threshold "${EPSS_THRESHOLD}" \
              --output "${EPSS_FINDINGS}" \
              "${inputs[@]}"
          fi

      - name: Upload EPSS Findings
        uses: actions/upload-artifact@v4
        with:
          name: epss-findings
          path: ${{ env.EPSS_FINDINGS }}
          if-no-files-found: ignore
          retention-days: 14

      - name: GitHub Issues + PR Comments (EPSS/KEV)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          EPSS_FINDINGS: ${{ env.EPSS_FINDINGS }}
        run: |
          set -euo pipefail
          if [ -f "${EPSS_FINDINGS}" ]; then
            python3 scripts/epss_gh_integration.py
          else
            echo "[INFO] EPSS findings missing; skip GH integration."
          fi

      - name: Gate Summary + Slack
        env:
          SLACK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          EPSS_FINDINGS: ${{ env.EPSS_FINDINGS }}
        run: |
          set -euo pipefail
          python3 scripts/gate_summary.py

# =====================================================================
# 5. DEFECTDOJO UPLOAD
# =====================================================================
  upload_to_defectdojo:
    name: Upload Traditional Scans â†’ DefectDojo
    needs: [security_scans, gate_and_summary]
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          path: all-reports

      - name: Import Traditional Scans to DefectDojo
        env:
          DEFECTDOJO_URL: ${{ env.DEFECTDOJO_URL }}
          DEFECTDOJO_API_KEY: ${{ env.DEFECTDOJO_API_KEY }}
          DEFECTDOJO_PRODUCT_ID: ${{ env.DEFECTDOJO_PRODUCT_ID }}
          DEFECTDOJO_ENGAGEMENT_NAME: ${{ env.DEFECTDOJO_ENGAGEMENT_NAME }}
        run: |
          set -euo pipefail
          python3 scripts/dd_traditional_import.py

  llm_to_defectdojo:
    name: Upload LLM Findings â†’ DefectDojo
    needs: [llm_sast]
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: llm-findings
          path: ${{ env.REPORT_DIR }}

      - name: Convert & Upload LLM Findings
        env:
          DEFECTDOJO_URL: ${{ env.DEFECTDOJO_URL }}
          DEFECTDOJO_API_KEY: ${{ env.DEFECTDOJO_API_KEY }}
          DEFECTDOJO_PRODUCT_ID: ${{ env.DEFECTDOJO_PRODUCT_ID }}
          DEFECTDOJO_ENGAGEMENT_NAME: ${{ env.DEFECTDOJO_ENGAGEMENT_NAME }}
          LLM_REPORT: ${{ env.LLM_REPORT }}
        run: |
          set -euo pipefail

          python3 scripts/dd_export.py \
            --input "${LLM_REPORT}" \
            --output "security-reports/llm-defectdojo.json"

          curl -sS -X POST "${DEFECTDOJO_URL}/api/v2/import-scan/" \
            -H "Authorization: Token ${DEFECTDOJO_API_KEY}" \
            -F "scan_type=Generic Findings Import" \
            -F "product=${DEFECTDOJO_PRODUCT_ID}" \
            -F "engagement_name=${DEFECTDOJO_ENGAGEMENT_NAME}" \
            -F "file=@security-reports/llm-defectdojo.json"

# =====================================================================
# 6. SECURITY SCORECARD + BOARD REPORT
# =====================================================================
  scorecard_and_report:
    name: Scorecard + Board Report
    needs: [gate_and_summary, upload_to_defectdojo, llm_to_defectdojo]
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: epss-findings
          path: ${{ env.REPORT_DIR }}
        continue-on-error: true

      - name: Prepare dirs
        run: |
          set -euo pipefail
          mkdir -p docs/data docs/reports
          # Stub minimal supaya script tidak crash bila sumber belum ada
          [ -f docs/data/owasp-latest.json ] || echo '{}' > docs/data/owasp-latest.json
          [ -f docs/data/defectdojo-sla-weekly.json ] || echo '{}' > docs/data/defectdojo-sla-weekly.json

      - name: Generate Scorecard JSON
        env:
          OWASP_LATEST: docs/data/owasp-latest.json
          EPSS_FINDINGS: ${{ env.EPSS_FINDINGS }}
          SLA_WEEKLY: docs/data/defectdojo-sla-weekly.json
          LLM_FINDINGS: ${{ env.LLM_REPORT }}
        run: |
          set -euo pipefail
          if ! python3 scripts/security_scorecard.py > docs/data/security-scorecard.json; then
            echo '{}' > docs/data/security-scorecard.json
          fi

      - name: Render Board MD
        run: |
          set -euo pipefail
          if ! python3 scripts/render_security_markdown.py \
            docs/data/security-scorecard.json > docs/reports/security-board-report.md; then
            echo "# Security Board Report\n\nReport generation failed." \
              > docs/reports/security-board-report.md
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: security-board-report
          path: docs/reports/security-board-report.md
          retention-days: 30

      - uses: actions/upload-artifact@v4
        with:
          name: security-scorecard-json
          path: docs/data/security-scorecard.json
          retention-days: 30

# =====================================================================
# 7. BUILD â†’ SIGN â†’ SBOM
# =====================================================================
  build_and_sign:
    name: Build + Sign + SBOM
    needs: gate_and_summary
    if: github.event.inputs.run_full_deploy == 'true'
    runs-on: self-hosted

    outputs:
      image_ref: ${{ steps.export.outputs.image_ref }}

    steps:
      - uses: actions/checkout@v4

      - name: Docker Login
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Install Cosign & Syft
        run: |
          set -euo pipefail
          mkdir -p $HOME/.local/bin
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh \
            | sh -s -- -b $HOME/.local/bin
          curl -sSfL https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64 \
            -o $HOME/.local/bin/cosign
          chmod +x $HOME/.local/bin/cosign
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Build and Push
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ env.DOCKERFILE_PATH }}
          push: true
          tags: |
            ${{ env.DOCKERHUB_REPO }}:latest
            ${{ env.DOCKERHUB_REPO }}:${{ env.IMAGE_TAG }}

      - name: Export Image Ref
        id: export
        run: |
          set -euo pipefail
          DIGEST="${{ steps.build.outputs.digest }}"
          IMAGE_REF="${{ env.DOCKERHUB_REPO }}@${DIGEST}"
          echo "image_ref=${IMAGE_REF}" >> $GITHUB_OUTPUT

      - name: Generate SBOM (CycloneDX)
        run: |
          set -euo pipefail
          syft "${{ env.DOCKERHUB_REPO }}:${{ env.IMAGE_TAG }}" -o cyclonedx-json=sbom.json

      - name: Sign Image + Attest SBOM
        env:
          COSIGN_EXPERIMENTAL: "1"
        run: |
          set -euo pipefail
          cosign sign --yes "${{ env.DOCKERHUB_REPO }}:${{ env.IMAGE_TAG }}"
          cosign attest --yes --predicate sbom.json --type cyclonedx \
            "${{ env.DOCKERHUB_REPO }}:${{ env.IMAGE_TAG }}"

      - uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.json
          retention-days: 30

# =====================================================================
# 8. DEPLOY
# =====================================================================
  deploy:
    name: Deploy (Ansible)
    needs: build_and_sign
    runs-on: self-hosted
    if: needs.build_and_sign.result == 'success'

    steps:
      - uses: actions/checkout@v4

      - name: Execute Ansible
        env:
          IMAGE_REF: ${{ needs.build_and_sign.outputs.image_ref }}
        run: |
          set -euo pipefail
          echo "Deploying image: ${IMAGE_REF}"
          if [ -z "${IMAGE_REF}" ]; then
            echo "[FALLBACK] IMAGE_REF empty, using latest"
            IMAGE_REF="${{ env.DOCKERHUB_REPO }}:latest"
          fi

          mkdir -p ~/.ssh
          echo "${{ secrets.ANSIBLE_SSH_KEY }}" > ~/.ssh/id_runner_temp
          chmod 600 ~/.ssh/id_runner_temp

          ansible-playbook -i ansible/inventory.ini ansible/site.yml \
            --private-key ~/.ssh/id_runner_temp \
            -e "image_ref=${IMAGE_REF}" \
            -e "db_password=${{ secrets.DB_PASSWORD }}" \
            -e "app_secret=${{ secrets.APP_SECRET_KEY }}" \
            -e "jwt_secret=${{ secrets.JWT_SECRET_KEY }}" \
            -e "dockerhub_username=${{ secrets.DOCKERHUB_USERNAME }}" \
            -e "dockerhub_token=${{ secrets.DOCKERHUB_TOKEN }}"

          rm -f ~/.ssh/id_runner_temp

      - name: Notify Slack on Success
        if: success()
        env:
          SLACK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          IMAGE_REF: ${{ needs.build_and_sign.outputs.image_ref }}
        run: |
          set -euo pipefail
          msg="ðŸš€ *Deployment Success!* (Run #${{ github.run_number }})\nâ€¢ *App:* ${{ env.APP_NAME }}\nâ€¢ *Image:* \`${IMAGE_REF}\`\nâ€¢ *Target:* ${{ env.APP_URL }}\nâ€¢ *Status:* Successfully deployed via Ansible."
          curl -sS -X POST -H 'Content-type: application/json' \
            --data "$(jq -n --arg text "$msg" '{text:$text}')" \
            "$SLACK_URL" >/dev/null

# =====================================================================
# 9. DAST (ZAP â†’ DefectDojo)
# =====================================================================
  dast_scan:
    name: DAST (OWASP ZAP)
    needs: deploy
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      - name: OWASP ZAP Baseline Scan
        run: |
          set -euo pipefail
          docker run --rm -v "$(pwd):/zap/wrk/:rw" \
            ghcr.io/zaproxy/zaproxy:stable zap-baseline.py \
            -t "${{ env.APP_URL }}" \
            -J zap_report.json || true

      - name: Upload DAST to DefectDojo
        run: |
          set -euo pipefail
          if [ ! -f zap_report.json ]; then
            echo "[SKIP] No ZAP report"
            exit 0
          fi

          curl -sS -X POST "${{ secrets.DEFECTDOJO_URL }}/api/v2/import-scan/" \
            -H "Authorization: Token ${{ secrets.DEFECTDOJO_API_KEY }}" \
            -F "active=true" \
            -F "verified=true" \
            -F "scan_type=ZAP Scan" \
            -F "product=${{ secrets.DEFECTDOJO_PRODUCT_ID }}" \
            -F "engagement_name=DAST-${{ github.run_number }}" \
            -F "file=@zap_report.json" >/dev/null

      - name: Final Cleanup (Disk Management)
        if: always()
        run: |
          set -euo pipefail
          rm -f zap_report.json || true
          docker image prune -f || true
